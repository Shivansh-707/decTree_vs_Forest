This project compares the performance of two popular machine learning algorithms — Decision Tree and Random Forest — using the Wine dataset from scikit-learn. 
The goal is to observe how ensemble methods like Random Forest typically outperform standalone models like Decision Tree in terms of accuracy and generalization.

Both models were tuned using GridSearchCV to find the best hyperparameters, and their performance was evaluated using cross-validation and test set accuracy. 
Visualizations such as bar charts and confusion matrices help illustrate the difference in their predictive power. 
The results clearly show that Random Forest achieves higher accuracy and better handles classification tasks compared to a single Decision Tree.
